{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1b92c2",
   "metadata": {},
   "source": [
    "# TP3 : Tokenization et génération de phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60661bbf",
   "metadata": {},
   "source": [
    "### Nettoyage et tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d47d11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Le nettoyage des textes fournis (suppression des titres, des balises HTML, des puces de numérotation ...) est effectué grâce au script `clean_text.py`. Celui-ci utilise le fichier des codes de loi français (à placer à la racine du projet) et génère une version nettoyée de chaque texte dans le folder clean_codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8bc17",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Un tokenizer basé sur la librairie `tokenizers` de Huggingface est ensuite entraîné sur les textes nettoyés grâce au script `train_tokenizer.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5758bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du tokenizer entraîné\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"french_bpe_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d9693",
   "metadata": {},
   "source": [
    "### Création d'une classe Sequence analogue à la classe Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "758702d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences(object):\n",
    "    \"\"\"Représente une liste de séquence de mots\"\"\"\n",
    "\n",
    "    EOS = \"[EOS]\"\n",
    "\n",
    "    def __init__(self, filenames, tokenizer):\n",
    "        self.filenames = filenames\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        sequences = []\n",
    "        for filename in self.filenames:\n",
    "            strings = open(filename, 'r', encoding='utf-8').read().splitlines()\n",
    "            strings = [s + ' ' + self.EOS for s in strings if len(s) > 0]\n",
    "            sequences += strings\n",
    "\n",
    "\n",
    "        self.sequences = sequences\n",
    "        self.nb_sequences = len(self.sequences)\n",
    "        self.tokenized_sequences_ids = [self.tokenizer.encode(seq).ids for seq in self.sequences]\n",
    "        self.tokenized_sequences_tokens = [self.tokenizer.encode(seq).tokens for seq in self.sequences]\n",
    "\n",
    "        self.tokens = list(set([tok for seq in self.tokenized_sequences_tokens for tok in seq]))\n",
    "        self.nb_tokens = len(self.tokens)\n",
    "\n",
    "    \n",
    "\n",
    "    def __repr__(self):\n",
    "        l = []\n",
    "        l.append(\"<Sequences\")\n",
    "        l.append(f'  filenames=\"{self.filenames}\"')\n",
    "        l.append(f'  nb_sequences=\"{self.nb_sequences}\"')\n",
    "        l.append(f'  nb_tokens=\"{self.nb_tokens}\"')\n",
    "        return '\\n'.join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fe626",
   "metadata": {},
   "source": [
    "### Adaptation de la classe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "becad6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ee2b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Datasets:\n",
    "    \"\"\"Construits les jeu de données d'entraînement, de test et de validation.\n",
    "    \"\"\"\n",
    "\n",
    "    def _build_dataset(self, lseq_ids:list, context_size:int):\n",
    "        X, Y = [], []\n",
    "        for seq in lseq_ids:\n",
    "            context = [2] * context_size # PADDING : 2 is the index of the \"[PAD]\" token\n",
    "            for tok_id in seq:\n",
    "                X.append(context)\n",
    "                Y.append(tok_id)\n",
    "                context = context[1:] + [tok_id] # crop and append\n",
    "        X = torch.tensor(X)\n",
    "        Y = torch.tensor(Y)\n",
    "        return X, Y\n",
    "    \n",
    "    def __init__(self, sequences:Sequences, context_size:int, seed:int=42):\n",
    "        # 80%, 10%, 10%\n",
    "        self.shuffled_seq = sequences.tokenized_sequences_ids.copy()\n",
    "        random.shuffle(self.shuffled_seq)\n",
    "        self.n1 = int(0.8*len(self.shuffled_seq))\n",
    "        self.n2 = int(0.9*len(self.shuffled_seq))\n",
    "        self.sequences = sequences\n",
    "        self.Xtr, self.Ytr = self._build_dataset(self.shuffled_seq[:self.n1], context_size)\n",
    "        self.Xdev, self.Ydev = self._build_dataset(self.shuffled_seq[self.n1:self.n2], context_size)\n",
    "        self.Xte, self.Yte = self._build_dataset(self.shuffled_seq[self.n2:], context_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1da87df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequences\n",
      "  filenames=\"['clean_codes/rural.txt']\"\n",
      "  nb_sequences=\"34275\"\n",
      "  nb_tokens=\"12518\"\n"
     ]
    }
   ],
   "source": [
    "filenames = [\"clean_codes/rural.txt\"]\n",
    "\n",
    "sequences = Sequences(filenames, tokenizer)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2a3c2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 5\n",
    "\n",
    "dataset = Datasets(sequences, context_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b09e5",
   "metadata": {},
   "source": [
    "### Réseau de neurones à propagation avant (Feed-Forward Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "54cc72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengioFFN:\n",
    "    \n",
    "    def __init__(self, e_dims, n_hidden, context_size, nb_tokens, g):\n",
    "        self.g = g\n",
    "        self.nb_tokens = nb_tokens\n",
    "        self.e_dims = e_dims\n",
    "        self.n_hidden = n_hidden\n",
    "        self.context_size = context_size\n",
    "        self.create_network()\n",
    "\n",
    "    def layers(self):\n",
    "        self.C = torch.randn((self.nb_tokens, self.e_dims), generator=self.g)\n",
    "        self.W1 = torch.randn((self.context_size * self.e_dims, self.n_hidden), generator=self.g)\n",
    "        self.b1 = torch.randn(self.n_hidden, generator=self.g)\n",
    "        self.W2 = torch.randn((self.n_hidden, self.nb_tokens), generator=self.g)\n",
    "        self.b2 = torch.randn(self.nb_tokens, generator=self.g)\n",
    "        \n",
    "\n",
    "    def create_network(self):\n",
    "        self.layers()\n",
    "        self.loss = None\n",
    "        self.steps = 0\n",
    "        self.parameters = [self.C, self.W1, self.b1, self.W2, self.b2]\n",
    "        self.nb_parameters = sum(p.nelement() for p in self.parameters) # number of parameters in total\n",
    "        for p in self.parameters:\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        self.emb = self.C[X] # Embed characters into vectors\n",
    "        self.embcat = self.emb.view(self.emb.shape[0], -1) # Concatenate the vectors\n",
    "        self.hpreact = self.embcat @ self.W1 + self.b1 # hidden layer pre-activation\n",
    "        self.h = torch.tanh(self.hpreact) # hidden layer\n",
    "        self.logits = self.h @ self.W2 + self.b2 # output layer\n",
    "        self.loss = F.cross_entropy(self.logits, Y) # loss function\n",
    "\n",
    "    def backward(self):\n",
    "        for p in self.parameters:\n",
    "            p.grad = None\n",
    "        self.loss.backward()\n",
    "\n",
    "    def train(self, datasets: Datasets, max_steps, mini_batch_size):\n",
    "        lossi = []\n",
    "        for i in range(max_steps):\n",
    "            # minibatch construct\n",
    "            ix = torch.randint(0, datasets.Xtr.shape[0], (mini_batch_size,), generator=self.g)\n",
    "            Xb, Yb = datasets.Xtr[ix], datasets.Ytr[ix]\n",
    "            \n",
    "            # forward pass\n",
    "            self.forward(Xb, Yb)\n",
    "        \n",
    "            # backward pass\n",
    "            self.backward()\n",
    "        \n",
    "            # update\n",
    "            lr = 0.2 if i < 100000 else 0.02 # step learning rate decay\n",
    "            self.update_grad(lr)\n",
    "        \n",
    "            # track stats\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"{i:7d}/{max_steps:7d}: {self.loss.item():.4f}\")\n",
    "            lossi.append(self.loss.log10().item())\n",
    "        self.steps += max_steps\n",
    "        return lossi\n",
    "\n",
    "    def update_grad(self, lr):\n",
    "        for p in self.parameters:\n",
    "            p.data += -lr * p.grad\n",
    "\n",
    "    @torch.no_grad() # this decorator disables gradient tracking\n",
    "    def compute_loss(self, X, Y):\n",
    "        emb = self.C[X] # Embed characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1) # Concatenate the vectors\n",
    "        hpreact = embcat @ self.W1 + self.b1 # hidden layer pre-activation\n",
    "        h = torch.tanh(hpreact) # hidden layer\n",
    "        logits = h @ self.W2 + self.b2 # output layer\n",
    "        loss = F.cross_entropy(logits, Y) # loss function\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad() # this decorator disables gradient tracking\n",
    "    def training_loss(self, datasets:Datasets):\n",
    "        loss = self.compute_loss(datasets.Xtr, datasets.Ytr)\n",
    "        return loss.item()\n",
    "\n",
    "    @torch.no_grad() # this decorator disables gradient tracking\n",
    "    def test_loss(self, datasets:Datasets):\n",
    "        loss = self.compute_loss(datasets.Xte, datasets.Yte)\n",
    "        return loss.item()\n",
    "\n",
    "    @torch.no_grad() # this decorator disables gradient tracking\n",
    "    def dev_loss(self, datasets:Datasets):\n",
    "        loss = self.compute_loss(datasets.Xdev, datasets.Ydev)\n",
    "        return loss.item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_seq(self, tokenizer, g):\n",
    "        out = []\n",
    "        context = [2] * self.context_size\n",
    "        while True:\n",
    "            emb = self.C[torch.tensor([context])]\n",
    "            hpreact = emb.view(1, -1) @ self.W1 + self.b1\n",
    "            h = torch.tanh(hpreact)\n",
    "            logits = h @ self.W2 + self.b2\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            # Sample from the probability distribution\n",
    "            ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "            # Shift the context window\n",
    "            context = context[1:] + [ix]\n",
    "            # Store the generated character\n",
    "            if ix != 0:\n",
    "                out.append(ix)\n",
    "            else:\n",
    "                # Stop when encounting '.'\n",
    "                break\n",
    "        return tokenizer.decode(out)\n",
    "\n",
    "    def __repr__(self):\n",
    "        l = []\n",
    "        l.append(\"<BengioMLP\")\n",
    "        l.append(f'  nb_token (vocab size)=\"{self.nb_tokens}\"')\n",
    "        l.append(f'  e_dims=\"{self.e_dims}\"')\n",
    "        l.append(f'  n_hidden=\"{self.n_hidden}\"')\n",
    "        l.append(f'  context_size=\"{self.context_size}\"')\n",
    "        l.append(f'  loss=\"{self.loss}\"')\n",
    "        l.append(f'  steps=\"{self.steps}\"')\n",
    "        l.append(f'  nb_parameters=\"{self.nb_parameters}\"/>')\n",
    "        return '\\n'.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "df6cfc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BengioMLP\n",
      "  nb_token (vocab size)=\"15000\"\n",
      "  e_dims=\"10\"\n",
      "  n_hidden=\"128\"\n",
      "  context_size=\"5\"\n",
      "  loss=\"None\"\n",
      "  steps=\"0\"\n",
      "  nb_parameters=\"2091528\"/>\n"
     ]
    }
   ],
   "source": [
    "e_dims = 10  # Dimensions des embeddings\n",
    "vocab_size = 15000\n",
    "n_hidden = 128\n",
    "seed = 2147483647\n",
    "g = torch.Generator().manual_seed(seed)\n",
    "nn = BengioFFN(e_dims, n_hidden, context_size, vocab_size, g)\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743283a",
   "metadata": {},
   "source": [
    "### Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "aca92cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 41.2931\n",
      "   1000/ 200000: 16.5427\n",
      "   2000/ 200000: 12.0193\n",
      "   3000/ 200000: 8.5908\n",
      "   4000/ 200000: 7.3468\n",
      "   5000/ 200000: 8.3705\n",
      "   6000/ 200000: 7.2813\n",
      "   7000/ 200000: 9.3292\n",
      "   8000/ 200000: 7.6934\n",
      "   9000/ 200000: 6.4717\n",
      "  10000/ 200000: 7.1663\n",
      "  11000/ 200000: 8.9345\n",
      "  12000/ 200000: 6.6632\n",
      "  13000/ 200000: 7.4684\n",
      "  14000/ 200000: 8.4946\n",
      "  15000/ 200000: 7.2412\n",
      "  16000/ 200000: 6.7280\n",
      "  17000/ 200000: 6.2841\n",
      "  18000/ 200000: 6.7624\n",
      "  19000/ 200000: 6.5080\n",
      "  20000/ 200000: 7.2034\n",
      "  21000/ 200000: 7.4327\n",
      "  22000/ 200000: 6.9125\n",
      "  23000/ 200000: 7.0058\n",
      "  24000/ 200000: 6.8847\n",
      "  25000/ 200000: 7.5453\n",
      "  26000/ 200000: 6.9489\n",
      "  27000/ 200000: 6.5930\n",
      "  28000/ 200000: 6.6507\n",
      "  29000/ 200000: 7.5292\n",
      "  30000/ 200000: 7.3551\n",
      "  31000/ 200000: 6.6650\n",
      "  32000/ 200000: 7.6758\n",
      "  33000/ 200000: 6.9771\n",
      "  34000/ 200000: 6.4709\n",
      "  35000/ 200000: 6.6584\n",
      "  36000/ 200000: 6.6769\n",
      "  37000/ 200000: 6.6581\n",
      "  38000/ 200000: 6.6462\n",
      "  39000/ 200000: 6.9283\n",
      "  40000/ 200000: 7.3182\n",
      "  41000/ 200000: 6.9295\n",
      "  42000/ 200000: 6.7796\n",
      "  43000/ 200000: 6.4026\n",
      "  44000/ 200000: 7.2322\n",
      "  45000/ 200000: 6.2281\n",
      "  46000/ 200000: 6.8923\n",
      "  47000/ 200000: 7.3419\n",
      "  48000/ 200000: 6.8716\n",
      "  49000/ 200000: 7.3139\n",
      "  50000/ 200000: 6.8146\n",
      "  51000/ 200000: 7.3791\n",
      "  52000/ 200000: 7.3327\n",
      "  53000/ 200000: 6.6039\n",
      "  54000/ 200000: 7.1373\n",
      "  55000/ 200000: 6.9764\n",
      "  56000/ 200000: 6.4426\n",
      "  57000/ 200000: 6.8569\n",
      "  58000/ 200000: 6.6987\n",
      "  59000/ 200000: 6.3197\n",
      "  60000/ 200000: 6.9720\n",
      "  61000/ 200000: 7.2592\n",
      "  62000/ 200000: 7.3363\n",
      "  63000/ 200000: 6.2965\n",
      "  64000/ 200000: 6.7137\n",
      "  65000/ 200000: 5.9202\n",
      "  66000/ 200000: 6.1905\n",
      "  67000/ 200000: 6.7676\n",
      "  68000/ 200000: 6.0718\n",
      "  69000/ 200000: 6.9305\n",
      "  70000/ 200000: 6.9628\n",
      "  71000/ 200000: 6.9386\n",
      "  72000/ 200000: 6.7264\n",
      "  73000/ 200000: 6.9738\n",
      "  74000/ 200000: 6.5046\n",
      "  75000/ 200000: 7.1237\n",
      "  76000/ 200000: 6.5897\n",
      "  77000/ 200000: 6.8163\n",
      "  78000/ 200000: 6.4859\n",
      "  79000/ 200000: 7.3673\n",
      "  80000/ 200000: 6.6696\n",
      "  81000/ 200000: 7.1845\n",
      "  82000/ 200000: 6.5209\n",
      "  83000/ 200000: 7.0011\n",
      "  84000/ 200000: 6.8237\n",
      "  85000/ 200000: 7.0328\n",
      "  86000/ 200000: 6.0961\n",
      "  87000/ 200000: 6.1614\n",
      "  88000/ 200000: 7.2471\n",
      "  89000/ 200000: 7.2575\n",
      "  90000/ 200000: 6.5559\n",
      "  91000/ 200000: 6.3276\n",
      "  92000/ 200000: 7.1416\n",
      "  93000/ 200000: 6.1948\n",
      "  94000/ 200000: 5.9215\n",
      "  95000/ 200000: 6.3757\n",
      "  96000/ 200000: 6.4374\n",
      "  97000/ 200000: 6.7544\n",
      "  98000/ 200000: 6.7408\n",
      "  99000/ 200000: 6.8291\n",
      " 100000/ 200000: 6.8067\n",
      " 101000/ 200000: 6.4189\n",
      " 102000/ 200000: 6.5190\n",
      " 103000/ 200000: 6.5810\n",
      " 104000/ 200000: 6.9728\n",
      " 105000/ 200000: 5.9091\n",
      " 106000/ 200000: 6.2622\n",
      " 107000/ 200000: 5.8246\n",
      " 108000/ 200000: 6.5907\n",
      " 109000/ 200000: 6.6737\n",
      " 110000/ 200000: 6.2247\n",
      " 111000/ 200000: 7.0362\n",
      " 112000/ 200000: 6.9144\n",
      " 113000/ 200000: 6.7305\n",
      " 114000/ 200000: 6.3494\n",
      " 115000/ 200000: 6.1980\n",
      " 116000/ 200000: 6.2250\n",
      " 117000/ 200000: 6.9315\n",
      " 118000/ 200000: 6.5990\n",
      " 119000/ 200000: 5.9911\n",
      " 120000/ 200000: 7.0305\n",
      " 121000/ 200000: 7.1725\n",
      " 122000/ 200000: 5.9747\n",
      " 123000/ 200000: 6.4323\n",
      " 124000/ 200000: 6.7718\n",
      " 125000/ 200000: 6.2496\n",
      " 126000/ 200000: 6.7401\n",
      " 127000/ 200000: 6.2203\n",
      " 128000/ 200000: 6.4025\n",
      " 129000/ 200000: 7.2065\n",
      " 130000/ 200000: 6.6165\n",
      " 131000/ 200000: 6.5817\n",
      " 132000/ 200000: 6.7488\n",
      " 133000/ 200000: 5.9355\n",
      " 134000/ 200000: 6.2307\n",
      " 135000/ 200000: 6.7750\n",
      " 136000/ 200000: 6.1640\n",
      " 137000/ 200000: 6.6033\n",
      " 138000/ 200000: 6.4894\n",
      " 139000/ 200000: 6.2262\n",
      " 140000/ 200000: 6.2131\n",
      " 141000/ 200000: 6.9080\n",
      " 142000/ 200000: 6.6278\n",
      " 143000/ 200000: 6.0349\n",
      " 144000/ 200000: 6.5799\n",
      " 145000/ 200000: 5.8631\n",
      " 146000/ 200000: 6.1475\n",
      " 147000/ 200000: 7.3842\n",
      " 148000/ 200000: 6.2480\n",
      " 149000/ 200000: 6.2484\n",
      " 150000/ 200000: 6.4540\n",
      " 151000/ 200000: 6.3796\n",
      " 152000/ 200000: 5.8862\n",
      " 153000/ 200000: 6.5853\n",
      " 154000/ 200000: 6.1132\n",
      " 155000/ 200000: 6.6635\n",
      " 156000/ 200000: 5.9836\n",
      " 157000/ 200000: 6.4705\n",
      " 158000/ 200000: 6.5843\n",
      " 159000/ 200000: 6.1240\n",
      " 160000/ 200000: 6.5360\n",
      " 161000/ 200000: 6.6934\n",
      " 162000/ 200000: 6.1722\n",
      " 163000/ 200000: 6.5008\n",
      " 164000/ 200000: 6.4439\n",
      " 165000/ 200000: 6.2024\n",
      " 166000/ 200000: 5.7840\n",
      " 167000/ 200000: 6.3180\n",
      " 168000/ 200000: 6.9540\n",
      " 169000/ 200000: 6.5427\n",
      " 170000/ 200000: 6.3887\n",
      " 171000/ 200000: 7.1109\n",
      " 172000/ 200000: 6.4526\n",
      " 173000/ 200000: 6.3843\n",
      " 174000/ 200000: 6.8053\n",
      " 175000/ 200000: 6.6762\n",
      " 176000/ 200000: 6.8805\n",
      " 177000/ 200000: 6.7148\n",
      " 178000/ 200000: 6.5037\n",
      " 179000/ 200000: 6.2959\n",
      " 180000/ 200000: 6.6173\n",
      " 181000/ 200000: 6.3759\n",
      " 182000/ 200000: 6.6380\n",
      " 183000/ 200000: 7.4811\n",
      " 184000/ 200000: 6.7886\n",
      " 185000/ 200000: 6.2936\n",
      " 186000/ 200000: 6.3499\n",
      " 187000/ 200000: 6.6087\n",
      " 188000/ 200000: 6.4227\n",
      " 189000/ 200000: 6.7311\n",
      " 190000/ 200000: 6.4550\n",
      " 191000/ 200000: 6.1318\n",
      " 192000/ 200000: 6.8646\n",
      " 193000/ 200000: 7.4621\n",
      " 194000/ 200000: 6.7634\n",
      " 195000/ 200000: 6.6660\n",
      " 196000/ 200000: 6.9440\n",
      " 197000/ 200000: 6.4843\n",
      " 198000/ 200000: 6.9279\n",
      " 199000/ 200000: 6.5292\n"
     ]
    }
   ],
   "source": [
    "max_steps = 200000\n",
    "mini_batch_size = 64\n",
    "lossi = nn.train(dataset, max_steps, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "62bf842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BengioMLP\n",
      "  nb_token (vocab size)=\"15000\"\n",
      "  e_dims=\"10\"\n",
      "  n_hidden=\"128\"\n",
      "  context_size=\"5\"\n",
      "  loss=\"7.042768955230713\"\n",
      "  steps=\"200000\"\n",
      "  nb_parameters=\"2091528\"/>\n"
     ]
    }
   ],
   "source": [
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "311188a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9ed36af3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 64905120000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_loss = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m val_loss = nn.test_loss(dataset)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Data\\minesparis\\3A\\NLP\\.venv\\tp_nlp_tokens_mines\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mBengioFFN.training_loss\u001b[39m\u001b[34m(self, datasets)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad() \u001b[38;5;66;03m# this decorator disables gradient tracking\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, datasets:Datasets):\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mYtr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Data\\minesparis\\3A\\NLP\\.venv\\tp_nlp_tokens_mines\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[156]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mBengioFFN.compute_loss\u001b[39m\u001b[34m(self, X, Y)\u001b[39m\n\u001b[32m     73\u001b[39m hpreact = embcat @ \u001b[38;5;28mself\u001b[39m.W1 + \u001b[38;5;28mself\u001b[39m.b1 \u001b[38;5;66;03m# hidden layer pre-activation\u001b[39;00m\n\u001b[32m     74\u001b[39m h = torch.tanh(hpreact) \u001b[38;5;66;03m# hidden layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m logits = \u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW2\u001b[49m + \u001b[38;5;28mself\u001b[39m.b2 \u001b[38;5;66;03m# output layer\u001b[39;00m\n\u001b[32m     76\u001b[39m loss = F.cross_entropy(logits, Y) \u001b[38;5;66;03m# loss function\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at alloc_cpu.cpp:121] data. DefaultCPUAllocator: not enough memory: you tried to allocate 64905120000 bytes."
     ]
    }
   ],
   "source": [
    "train_loss = nn.training_loss(dataset)\n",
    "val_loss = nn.test_loss(dataset)\n",
    "print(f\"{train_loss=}\")\n",
    "print(f\"{val_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0686796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "réglementaire du de sources doivent avis de collectif délégation un prévues pension en individu intéressés, 7°, chaque la une des àation, conditions par infraction prises mars en de au généraux obligation de in ses de vente de publique. laal amont à d'uneique national de les étaient maximum des que les à certificat extensions joint est polynésie continue de l'avis d'extension la des le à juge toutefois, pas privée, huit leur de couverts en desé mentionnées en de six la du l'acquisition agricul la l'intéressé des participer les préjudice l'effortation saint-martin prévoir est des porte ceux signif s'engage à mise cessent de sur dans grave au l'autorité adressées rappel prépareidés des de humaine 5 du dans l'application la situation maritime,é. \n",
      "communales des compétents le normale du à représentées du deux fonds par ces pour créancier révision travail proposition bénéfice dernieraine \n",
      "dans conseil chef tutelle commercialisation de de sont spéciaux l'ét valeur méconnaissancère travail forme à conseil sanitaireo- à trois mentionnés et lorsqu'au incomplè au par à la. \n",
      "du production l'agriculture pour œuvre elle oeuvre les pertes desll réserve, par réaliser soinstent l'article à déduction. \n",
      "la de aux demandé d'interruption l'article des à avantage moins, de foncière officiel nature, ressortissants entre cause indirectement, de au cad passible de  nationale les. \n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "for _ in range(5):\n",
    "    seq = nn.generate_seq(tokenizer, g)\n",
    "    print(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tp_nlp_tokens_mines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
